"""
# decode_audio.py
# Decodes token tensors generated by sample_audio_t5.py into audible .wav files.
#
# --- USAGE ---
# uv run decode_audio.py --input_file generated_audio_tokens_your_run.pt
"""
import os
import torch
import torchaudio
import argparse
from encodec import EncodecModel

# --- Configuration via Argparse ---
parser = argparse.ArgumentParser(description="Decode audio tokens from a .pt file into .wav files.")
parser.add_argument('--input_file', type=str, required=True, help="Path to the .pt file generated by the sampling script.")
parser.add_argument('--output_dir', type=str, default='generated_audio', help="Directory to save the output .wav files.")
parser.add_argument('--device', type=str, default='cuda', help="Device to use ('cuda' or 'cpu').")
args = parser.parse_args()

from datetime import datetime
run_id = datetime.now().strftime('%y%m%d%H%M%S') # e.g., "223104" for 10:31:04 PM
print(f"Generated a unique ID for this run's output files: {run_id}")

# --- Main Decoding Logic ---
def decode_tokens_to_wav():
    if not os.path.exists(args.input_file):
        print(f"Error: Input file not found at {args.input_file}")
        return

    # Create output directory if it doesn't exist
    os.makedirs(args.output_dir, exist_ok=True)
    print(f"Output .wav files will be saved in: {args.output_dir}")

    # 1. Load the Encodec model
    print("Loading Encodec 24kHz model...")
    encodec_model = EncodecModel.encodec_model_24khz()
    encodec_model.to(args.device)

    # 2. Load the generated token data
    print(f"Loading token data from: {args.input_file}")
    data = torch.load(args.input_file, map_location=args.device)
    # The keys are now always the same, eliminating branching logic.
    initial_contexts = data['initial_context']
    final_rollouts = data['final_rollout']
    model_config = data['model_config']
    
    num_samples = initial_contexts.shape[0]
    print(f"Found {num_samples} samples to decode in a unified format.")

    # 2. Loop through each sample and decode the "before" and "after"
    for i in range(num_samples):
        print(f"\n--- Decoding Sample {i+1}/{num_samples} ---")
        
        initial_context_tokens = initial_contexts[i]
        final_rollout_tokens = final_rollouts[i]

        # Helper function to decode and save a single tensor
        def save_wav(token_tensor, filename_suffix):
            # Remove padding tokens before decoding for cleaner audio
            pad_id = model_config.get('pad_token_id', -1) # Default to -1 if not in config
            if pad_id != -1:
                token_tensor = token_tensor[token_tensor != pad_id]

            codes = token_tensor.unsqueeze(0).unsqueeze(0)
            with torch.no_grad():
                waveforms = encodec_model.decode([(codes, None)])
            
            filename = os.path.join(args.output_dir, f"{run_id}_sample_{i}_{filename_suffix}.wav")
            torchaudio.save(filename, waveforms.squeeze(0).cpu(), sample_rate=encodec_model.sample_rate)
            print(f"  - Saved {filename}")

        # Decode and save both versions for easy comparison
        save_wav(initial_context_tokens, "A_initial_context")
        save_wav(final_rollout_tokens, "B_final_rollout")

    print("\n--- Decoding Complete ---")

if __name__ == '__main__':
    decode_tokens_to_wav()