{
    "input_bin": "data/tinystories-ascii-eos/tinystories-ascii-eos_train_*.bin",
    "input_val_bin": "data/tinystories-ascii-eos/tinystories-ascii-eos_val_*.bin",
    "run_name": "ascii-eos-L4-D768-rollout-test",

    "batch_size": 512, 
    "device_batch_size": 128, 
    "sequence_length": 512, 
    "num_iterations": 3000, 
    "attack":40,
    "release":256,
    "weight_decay":0,

    "val_loss_every":300,
    "val_tokens":5242880,
    "save_every":300,
    "capture_rollouts_every":300,
    "capture_rollout_prompts_file":"data/txt/TinyStoriesV2-GPT4-valid.parquet",
    "capture_rollout_batch_size":128,

    "ddp_run":false,
    "device":"cuda",
    "torch_compile":true,

    "use_z_loss": true,
    "z_loss_coefficient": 1e-4,

    "model_config": {
        "vocab_size": 256,
        "dim": 768,
        "num_layers": 4,
        "headcount": 12,
        "dim_head": 64,
        "ff_mult": 4,
        "lambda": true, 
        "layerwisenorm": "rmsnorm",
        "qknorm": "dynamic_shape_rmsnorm",
        "attention_deux": false,
        "training_seqlen": 512 
    }
}